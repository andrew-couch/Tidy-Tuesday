---
title: "TidyTuesdayMulticlassClassification"
author: "Andrew Couch"
date: "10/19/2020"
output: html_document
---

Video: https://www.youtube.com/watch?v=ntk_1xLQBwo&list=PLJfshcspBCYeJeO8YFT5e5HxuYOb5a_1W&index=20&t=560s

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidymodels)
library(textrecipes)
library(textdata)
library(themis)

df <- read_csv("harrypotter.csv")
```

```{r}
df <- df %>% 
  select(house, text) %>% 
  filter(house != "No Entry")
```


```{r}
df %>% 
  count(house) %>% 
  ggplot(aes(x = house, y = n)) + 
  geom_col()
```




```{r}
# Download word embeddigns
#textdata::embedding_glove27b()
```


# Create train and test splits
```{r}
set.seed(19)
tidy_split <- initial_split(df, strata = house)
train_data <- training(tidy_split)
test_data <- testing(tidy_split)

train_data <- recipe(house~., data = train_data) %>% 
  step_downsample(house) %>% 
  prep() %>% 
  juice()

k_folds_data <- vfold_cv(train_data)
```

# Pre-process text data
```{r}
hash_rec <- recipe(house~., data = train_data) %>% 
  step_tokenize(text) %>% 
  step_stem(text) %>% 
  step_stopwords(text) %>% 
  step_tokenfilter(text, max_tokens = 1000) %>% 
  step_texthash(text, num_terms = 100) 

embeddings_rec <- recipe(house~., data = train_data) %>% 
  step_tokenize(text) %>% 
  step_stem(text) %>% 
  step_stopwords(text) %>% 
  step_tokenfilter(text, max_tokens = 1000) %>% 
  step_word_embeddings(text, embeddings = embedding_glove27b())


```


# Define models
```{r}
logistic_model <- multinom_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet") %>% 
  set_mode("classification")

knn_model <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine("kknn") %>% 
  set_mode("classification")

xgboost_model <- boost_tree(trees = tune(), learn_rate = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")
```

# Define Grids
```{r}
logistic_grid <- grid_regular(parameters(logistic_model), levels = 3)
knn_grid <- grid_regular(parameters(knn_model), levels = 5, filter = c(neighbors > 1))
xgboost_grid <- grid_regular(parameters(xgboost_model), levels = 3, filter = c(trees > 1))
```

# Define tuning process
```{r}
model_control <- control_grid(save_pred = TRUE)
model_metrics <- metric_set(accuracy, sens, spec, mn_log_loss, roc_auc)
```

# Tune Models
```{r}
# Tune hash models
linear_hash_res <- tune_grid(
  logistic_model,
  hash_rec,
  grid = logistic_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)

knn_hash_res <- tune_grid(
  knn_model,
  hash_rec,
  grid = knn_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)

xgboost_hash_res <- tune_grid(
  xgboost_model,
  hash_rec,
  grid = xgboost_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)

# Tune embed models
linear_embed_res <- tune_grid(
  logistic_model,
  embeddings_rec,
  grid = logistic_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)

knn_embed_res <- tune_grid(
  knn_model,
  embeddings_rec,
  grid = knn_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)

xgboost_embed_res <- tune_grid(
  xgboost_model,
  embeddings_rec,
  grid = xgboost_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)

```



```{r}
load("multi.Rdata")
```

```{r}
linear_hash_res %>% show_best("roc_auc")
knn_hash_res %>% show_best("roc_auc")
xgboost_hash_res %>% show_best("roc_auc")

linear_embed_res %>% show_best("roc_auc")
knn_embed_res %>% show_best("roc_auc")
xgboost_embed_res %>% show_best("roc_auc")
```

```{r}
final_param <- xgboost_hash_res %>% show_best("roc_auc") %>% slice(1) %>% select(trees, learn_rate)

xgboost_hash_res %>% 
  collect_predictions() %>% 
  inner_join(final_param) %>% 
  group_by(id) %>% 
  conf_mat(truth = house, estimate = .pred_class) %>% 
  mutate(tidied = map(conf_mat, tidy)) %>% 
  unnest(tidied)

```


# Evaluate Confusion Matrix
```{r}
xgboost_hash_res %>% 
  collect_predictions() %>% 
  inner_join(final_param) %>% 
  conf_mat(truth = house, estimate = .pred_class) 
```



```{r}

final_model <- workflow() %>% 
  add_model(xgboost_model) %>% 
  add_recipe(hash_rec)


final_model <- finalize_workflow(final_model, final_param)

```

# Evaluate Final Model
```{r}
final_res <- last_fit(final_model, tidy_split)
```

```{r}
final_res %>% collect_metrics()
```

```{r}
final_res %>% 
  collect_predictions() %>% 
  conf_mat(truth = house, estimate = .pred_class)
```








