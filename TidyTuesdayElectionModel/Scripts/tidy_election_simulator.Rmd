---
title: "Election Model"
author: "Andrew Couch"
date: "10/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages
```{r}
library(tidyverse)
library(lubridate)
library(caret)
library(glmnet)
library(here)
```

# Data
```{r}
all_polls <- read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQ56fySJKLL18Lipu1_i3ID9JE06voJEz2EXm6JW4Vh11zmndyTwejMavuNntzIWLY0RyhA1UsVEen0/pub?gid=0&single=true&output=csv') %>%
  filter(grepl('phone|online',tolower(mode)))

states2016 <- read_csv(here('Data/2016.csv')) %>%
  mutate(score = clinton_count / (clinton_count + trump_count),
         national_score = sum(clinton_count)/sum(clinton_count + trump_count),
         delta = score - national_score,
         share_national_vote = (total_count*(1+adult_pop_growth_2011_15))
         /sum(total_count*(1+adult_pop_growth_2011_15))) %>%
  arrange(state) 

state_weights <- c(states2016$share_national_vote / sum(states2016$share_national_vote))
names(state_weights) <- states2016$state

coefs <- read_csv(here('data/state_coefs.csv'))

state_evs <- read_csv(here('data/state_evs.csv'))
```

# Parameters
```{r}
RUN_DATE <- as_date(Sys.Date()) 

# this much daily sd in election polls
SD_AT_DAY_300 <- 0.1 
SD_AT_DAY_0 <- 0
DAILY_SD <- (SD_AT_DAY_300 - SD_AT_DAY_0) / 300
DAILY_SD * c(0,100,200,300)

# number of simulations to run
NUM_SIMS <- 10000

# number of cores to use
NUM_CORES <- min(6, parallel::detectCores())

# whether to burn all the models up and start over
REDO_ALL_MODELS <- FALSE
```

# Data Wrangling
```{r}
days_til_election <- as.numeric(ymd('2020-11-03') - RUN_DATE)
start_date <- ymd("2020-01-01")

todays_polls <- all_polls %>% 
  filter(as_date(as_datetime(all_polls$entry.date.time..et., format='%m/%d/%Y %H:%M:%S')) <= RUN_DATE) %>%
  mutate(date = mdy(end.date)) %>% 
  filter(!is.na(biden),!is.na(trump)) %>% 
  mutate(weight = sqrt(number.of.observations / mean(number.of.observations,na.rm=T)))
  
regression_weight <-  3

average_polls <- function(v_date){
  
  todays_polls %>%
    mutate(date_entered = as_date(as_datetime(todays_polls$entry.date.time..et., format='%m/%d/%Y %H:%M:%S')) ) %>%
    filter(date_entered <= v_date) %>%
    filter(state == '--') %>%
    mutate(decayed_weight = exp( as.numeric(v_date - mdy(end.date))*-0.1)) %>%
    summarise(mean_biden_margin = weighted.mean(biden-trump,weight*decayed_weight,na.rm=T)) %>%
    pull(mean_biden_margin)/100
  
  
}

national_poll_average <- tibble(date = as_date(start_date:RUN_DATE)) %>% 
  mutate(national_biden_margin = map_dbl(date, average_polls))

# now filter dates
todays_polls <- todays_polls %>% filter(mdy(end.date) >= start_date)

# get the last one for later on
v_national_biden_margin <- national_poll_average %>% slice(nrow(.)) %>% pluck(2,1)

national_poll_average_deltas <- national_poll_average %>% 
  mutate(national_biden_margin_delta = v_national_biden_margin - national_biden_margin)

state_averages <- todays_polls %>%
  filter(state != '--') %>%
  # trend line adjust
  left_join(national_poll_average_deltas) %>%
  mutate(biden_margin = (biden-trump) + national_biden_margin_delta) %>%
  # average
  group_by(state) %>%
  mutate(decayed_weight = exp( as.numeric(RUN_DATE - mdy(end.date))*-0.1)) %>%
  summarise(mean_biden_margin = weighted.mean(biden_margin,weight*decayed_weight,na.rm=T)/100,
            num_polls = n(),
            sum_weights = sum(weight,na.rm=T))

# get 2016 results
results <- politicaldata::pres_results %>% 
  filter(year == 2016) %>%
  mutate(clinton_margin = dem-rep) %>%
  select(state, clinton_margin)

# bind everything together
# make log pop density
state <- results %>%
  left_join(state_averages, by = "state") %>%
  mutate(dem_lean_2016 = clinton_margin - 0.021,
         dem_lean_2016_polls = mean_biden_margin - v_national_biden_margin) %>%
  left_join(coefs, by = "state")


# also create a dataset of all the state polls for the model
state_polls <- todays_polls %>%
  filter(state != '--') %>%
  left_join(results, by = "state") %>%
  mutate(mean_biden_margin = biden_margin/100,
         sum_weights = weight,
         dem_lean_2016 = clinton_margin - 0.021,
         dem_lean_2016_polls = mean_biden_margin - v_national_biden_margin) %>%
  left_join(coefs, by = "state")

stepwise_model <- step(lm(mean_biden_margin ~. - sum_weights,
                          data = state %>%
                            select(mean_biden_margin, black_pct, college_pct,
                                   hisp_other_pct, pct_white_evangel,pop_density,
                                   white_pct,wwc_pct,sum_weights) %>%
                            mutate_at(vars(contains("pct"),contains("pop_density")), 
                                      ~(.x - mean(.x))/sd(.x)) %>%
                            na.omit(),
                          weight = sum_weights))

testing <- state %>% 
  select(state,mean_biden_margin,black_pct,college_pct,
         hisp_other_pct,median_age,pct_white_evangel,
         pop_density,white_pct,wwc_pct,sum_weights) %>%
  mutate_at(vars(contains("_pct"), contains("pop_density"), contains("median_age")), ~(.x - mean(.x))/sd(.x))

# training is the poll data
training <- testing %>% na.omit()

glmnet_model <- train(mean_biden_margin ~  black_pct + college_pct + 
                        hisp_other_pct + pct_white_evangel + pop_density + 
                        white_pct + wwc_pct,
                      data = training,
                      weights = sum_weights,
                      method = "glmnet",
                      metric = "RMSE",
                      trControl = trainControl(method="LOOCV"),
                      preProcess = c("center", "scale"),
                      tuneLength = 10)

# combine predictions from the two models
preds <- testing %>%
  mutate(aic_pred = predict(object=stepwise_model,newdata=.),
         glmnet_pred = predict(object=glmnet_model,newdata=testing),
         pred = (aic_pred + glmnet_pred)/2) %>%
  pull(pred)

# and average the demographic predictions with the implied margin from partisan lean
# giving more weight to the partisan lean until we have a ton of polls to shore up the regression
demo_weight <- min( sum(state$sum_weights,na.rm=T) / (sum(state$sum_weights,na.rm=T) + 100), 0.5)
partisan_weight <- 1 - demo_weight

preds <- (preds * demo_weight) + ((state$dem_lean_2016 + v_national_biden_margin) * partisan_weight)

# make the projections
testing$proj_mean_biden_margin <- preds

# average predictions with the polls ------------------------------------
state <- state %>%
  # append the predictions
  left_join(testing %>% select(state,proj_mean_biden_margin), by = "state") %>%
  # make some mutations
  mutate(sum_weights = ifelse(is.na(sum_weights),0,sum_weights),
         mean_biden_margin = ifelse(is.na(mean_biden_margin),999,mean_biden_margin),
         poll_weight = sum_weights / (sum_weights + regression_weight),
         demo_regression_weight = regression_weight / (sum_weights + regression_weight),
         mean_biden_margin_hat = (mean_biden_margin * poll_weight ) + (proj_mean_biden_margin * demo_regression_weight),
         mean_biden_margin = ifelse(mean_biden_margin == 999,NA,mean_biden_margin))


# adjust state projections to match average of national vote 
og_national_biden_margin <- national_poll_average %>% slice(nrow(.)) %>% pluck(2,1)

implied_national_biden_margin <- weighted.mean(state$mean_biden_margin_hat,state_weights) 

# regress the state predictions back toward the national average
natl_diff <- function(par, 
                      dat = state, 
                      weights = state_weights,
                      target_natl = og_national_biden_margin,
                      current_natl = implied_national_biden_margin){
  
  dat$mean_biden_margin_hat_shift <- dat$mean_biden_margin_hat + (target_natl - current_natl)*par
  
  #print(weighted.mean(dat$mean_biden_margin_hat, weights) )
  #print(weighted.mean(dat$mean_biden_margin_hat_shift, weights) )
  
  return( abs( weighted.mean(dat$mean_biden_margin_hat_shift, weights) - target_natl) )
  # return( dat$mean_biden_margin_hat )
  
}

multiplier <- optim(par = 1,fn = natl_diff,method = "Brent",upper = 5, lower = -5)$par

state$mean_biden_margin_hat <- state$mean_biden_margin_hat + (og_national_biden_margin - implied_national_biden_margin)*multiplier

# save margin for later
national_biden_margin <- weighted.mean(state$mean_biden_margin_hat,state_weights)

# generate new state lean variable based on adjusted biden national margin
state$dem_lean_2016 <-  state$mean_biden_margin_hat - national_biden_margin 

# clean up estimates
final <- state %>%
  select(state,region,clinton_margin,dem_lean_2016,
         mean_biden_margin = mean_biden_margin_hat,
         dem_lean_2016_polls,
         dem_lean_2016, 
         num_polls,
         pop_density,
         wwc_pct) %>%
  mutate(shift = dem_lean_2016 - dem_lean_2016) %>%
  left_join(state_evs)
```

```{r}
# errors
national_error <- sqrt((0.025^2) + ((DAILY_SD * days_til_election)^2)) # national error + drift
regional_error <- (0.025) 
state_error <- (0.03) 

# sims
national_errors <- rnorm(NUM_SIMS, 0, national_error)
regional_errors <- replicate(NUM_SIMS, rnorm(length(unique(final$region)), 0, regional_error))
state_errors <- replicate(NUM_SIMS, rnorm(51, 0, state_error))

simulate_polling_errors <- function(state_errors, regional_errors, national_errors, state_region) {
  states <- unique(state_region$state)
  
  regions <- unique(state_region$region)
  
  state_errors <- state_errors %>%
    t() %>%
    as_tibble(.name_repair = "minimal") %>%
    set_names(~ states) %>%
    mutate(sim = row_number()) %>%
    pivot_longer(-sim, names_to = "state", values_to = "state_error")
  
  regional_errors <- regional_errors %>%
    t() %>%
    as_tibble(.name_repair = "minimal") %>%
    set_names(~ regions) %>%
    mutate(sim = row_number()) %>%
    pivot_longer(-sim, names_to = "region", values_to = "regional_error")
  
  national_errors <- tibble(sim = 1:length(national_errors), national_error = national_errors)
  
  state_region %>%
    left_join(state_errors, by = "state") %>%
    left_join(regional_errors, by = c("region", "sim")) %>%
    left_join(national_errors, by = "sim") %>%
    select(sim, state, region, state_error, regional_error, national_error)
}

state_region <- final %>%
  ungroup() %>%
  select(state, region) %>%
  distinct()

simulated_polling_errors <- simulate_polling_errors(state_errors, regional_errors, national_errors, state_region)

sims <- simulated_polling_errors %>%
  left_join(final %>% select(state, dem_lean_2016), by = "state") %>%
  mutate(proj_biden_margin = dem_lean_2016 + national_biden_margin,
         error = state_error + regional_error + national_error,
         sim_biden_margin = proj_biden_margin + error) %>%
  group_by(state) %>%
  mutate(draw = row_number()) %>%
  left_join(state_evs, by='state') %>%
  left_join(enframe(state_weights, 'state', 'weight'), by = "state") %>%
  group_by(draw) %>%
  mutate(dem_nat_pop_margin = weighted.mean(sim_biden_margin, weight)) %>%
  select(state, sim_biden_margin, draw, ev, weight, dem_nat_pop_margin)
```

```{r}
simulate_tails <- function(national_error, regional_error, state_error){
  national_errors <- rnorm(NUM_SIMS, 0, national_error)
  regional_errors <- replicate(NUM_SIMS, rnorm(length(unique(final$region)), 0, regional_error))
  state_errors <- replicate(NUM_SIMS, rnorm(51, 0, state_error))
  
  simulate_polling_errors(state_errors, regional_errors, national_errors, state_region) %>% 
    left_join(final %>% select(state, dem_lean_2016), by = "state") %>%
    mutate(proj_biden_margin = dem_lean_2016 + national_biden_margin,
           error = state_error + regional_error + national_error,
           sim_biden_margin = proj_biden_margin + error) %>%
    group_by(state) %>%
    mutate(draw = row_number()) %>%
    left_join(state_evs, by='state') %>%
    left_join(enframe(state_weights, 'state', 'weight'), by = "state") %>%
    group_by(draw) %>%
    mutate(dem_nat_pop_margin = weighted.mean(sim_biden_margin, weight)) %>%
    select(state, sim_biden_margin, draw, ev, weight, dem_nat_pop_margin) %>% 
    mutate(won_state = if_else(sim_biden_margin > 0, "Biden_State", "Trump_State")) %>% 
    pivot_wider(names_from = won_state, values_from = ev, values_fill = 0) %>% 
    group_by(draw) %>% 
    mutate(Trump_National = sum(Trump_State),
           Biden_National = sum(Biden_State)) %>% 
    ungroup() %>% 
    mutate(won_state = if_else(Trump_State == 0, "Biden", "Trump"),
           won_election = if_else(Biden_National >= 270, "Biden", "Trump")) %>% 
    select(draw, state, won_state, won_election) %>% 
    group_by(state) %>% 
    count(won_state, won_election) %>% 
    mutate(prob = n / sum(n)) %>% 
    ungroup()
}


error_df <- tibble(national_error_tail = c(.01, .025, .05),
       regional_error_tail = c(.01, .025, .05),
       state_error_tail = c(.01, .03, .05)) %>% 
  mutate(data = pmap(list(national_error_tail, regional_error_tail, state_error_tail), simulate_tails)) %>% 
  unnest(data)
```


```{r}
sims %>% 
  mutate(won_state = if_else(sim_biden_margin > 0, "Biden_State", "Trump_State")) %>% 
  pivot_wider(names_from = won_state, values_from = ev, values_fill = 0) %>% 
  group_by(draw) %>% 
  mutate(Trump_National = sum(Trump_State),
         Biden_National = sum(Biden_State)) %>% 
  ungroup() %>% 
  mutate(won_state = if_else(Trump_State == 0, "Biden", "Trump"),
         won_election = if_else(Biden_National >= 270, "Biden", "Trump")) %>% 
  select(draw, state, won_state, won_election) %>% 
  group_by(state) %>% 
  count(won_state, won_election) %>% 
  mutate(prob = n / sum(n)) %>% 
  ungroup() %>% 
  filter(state == "FL") %>% 
  select(won_state, won_election, prob) %>% 
  pivot_wider(names_from = won_state, values_from = prob)
```

```{r}
sims %>% 
  mutate(won_state = if_else(sim_biden_margin > 0, "Biden_State", "Trump_State")) %>% 
  pivot_wider(names_from = won_state, values_from = ev, values_fill = 0) %>% 
  group_by(draw) %>% 
  mutate(Trump_National = sum(Trump_State),
         Biden_National = sum(Biden_State)) %>% 
  ungroup() %>% 
  mutate(won_state = if_else(Trump_State == 0, "Biden", "Trump"),
         won_election = if_else(Biden_National >= 270, "Biden", "Trump")) %>% 
  select(draw, Trump_National, Biden_National) %>% 
  pivot_longer(-draw) %>% 
  ggplot(aes(x = value, color = name)) + 
  geom_density()
```

```{r}
sims %>% 
  mutate(won_state = if_else(sim_biden_margin > 0, "Biden_State", "Trump_State")) %>% 
  pivot_wider(names_from = won_state, values_from = ev, values_fill = 0) %>% 
  group_by(draw) %>% 
  mutate(Trump_National = sum(Trump_State),
         Biden_National = sum(Biden_State)) %>% 
  ungroup() %>% 
  mutate(won_state = if_else(Trump_State == 0, "Biden", "Trump"),
         won_election = if_else(Biden_National >= 270, "Biden", "Trump")) %>% 
  select(draw, state, won_state, won_election) %>% 
  group_by(state) %>% 
  count(won_state, won_election) %>% 
  mutate(prob = n / sum(n)) %>% 
  ungroup() %>% 
  filter(state %in% c("FL", "IA", "OH", "PA")) %>% 
  arrange(desc(prob)) %>% 
  filter(won_election == "Trump")
```


```{r}
sims %>% 
  mutate(won_state = if_else(sim_biden_margin > 0, "Biden_State", "Trump_State")) %>% 
  pivot_wider(names_from = won_state, values_from = ev, values_fill = 0) %>% 
  group_by(draw) %>% 
  mutate(Trump_National = sum(Trump_State),
         Biden_National = sum(Biden_State)) %>% 
  ungroup() %>% 
  mutate(won_state = if_else(Trump_State == 0, "Biden", "Trump"),
         won_election = if_else(Biden_National >= 270, "Biden", "Trump")) %>% 
  select(draw, state, won_state, won_election) %>% 
  group_by(state) %>% 
  count(won_state, won_election) %>% 
  mutate(prob = n / sum(n)) %>% 
  ungroup() %>% 
  filter(won_state == "Trump", won_election == "Biden") %>% 
  arrange(desc(prob))
```




